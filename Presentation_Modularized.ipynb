{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:16.807370Z",
     "start_time": "2025-08-14T05:11:16.742449Z"
    }
   },
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "def create_database(db_name=\"thematic_yearly_survey\", user=\"postgres\", password=\"PUT OWN PASSWORD\", host=\"localhost\", port=\"5432\"):\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"postgres\",  # connect to default db\n",
    "        user=user,\n",
    "        password=password,\n",
    "        host=host,\n",
    "        port=port\n",
    "    )\n",
    "    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(f\"SELECT 1 FROM pg_database WHERE datname='{db_name}'\")\n",
    "    exists = cur.fetchone()\n",
    "    if not exists:\n",
    "        cur.execute(f\"CREATE DATABASE {db_name}\")\n",
    "        print(f\" Database '{db_name}' created.\")\n",
    "    else:\n",
    "        print(\" Database already exists.\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:21.800649Z",
     "start_time": "2025-08-14T05:11:18.866656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import psycopg2\n",
    "from psycopg2.extras import Json\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "FOLDER = \".\"\n",
    "comment_keywords = [\"comment\", \"feedback\", \"remark\"]\n",
    "binary_options = [\"yes\", \"no\", \"male\", \"female\"]\n",
    "\n",
    "def clean_nan(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_nan(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_nan(v) for v in obj]\n",
    "    elif isinstance(obj, float) and (math.isnan(obj) or pd.isna(obj)):\n",
    "        return None\n",
    "    elif isinstance(obj, (pd._libs.missing.NAType, type(pd.NA))):\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "def categorize_sentiment(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return {\"label\": None, \"polarity\": None}\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        label = \"positive\"\n",
    "    elif polarity < -0.1:\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "    return {\"label\": label, \"polarity\": round(polarity, 3)}\n",
    "\n",
    "def is_comment(col, series):\n",
    "    if any(key in col.lower() for key in comment_keywords):\n",
    "        return True\n",
    "    if pd.api.types.is_object_dtype(series):\n",
    "        non_null_series = series.dropna().astype(str)\n",
    "        sample = non_null_series.sample(n=min(20, len(non_null_series)), random_state=1)\n",
    "        avg_len = sample.map(len).mean() if not sample.empty else 0\n",
    "        long_texts = sample[sample.map(len) > 30]\n",
    "        return avg_len > 20 and len(long_texts) > 0\n",
    "    return False\n",
    "\n",
    "def is_quantitative(series):\n",
    "    return pd.api.types.is_numeric_dtype(series) and series.dropna().between(1, 10).all()\n",
    "\n",
    "def is_demographic(series):\n",
    "    if series.dtype == object:\n",
    "        unique_vals = series.dropna().astype(str).str.lower().unique().tolist()\n",
    "        return len(unique_vals) <= 10 or all(val in binary_options for val in unique_vals)\n",
    "    return False\n",
    "\n",
    "def ingest_excel_to_postgres(db_name=\"thematic_yearly_survey\", user=\"postgres\", password=\"PUT OWN PASSWORD\", host=\"localhost\", port=\"5432\"):\n",
    "    conn = psycopg2.connect(dbname=db_name, user=user, password=password, host=host, port=port)\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for file in os.listdir(FOLDER):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            print(f\"\\n Processing file: {file}\")\n",
    "            basename = os.path.splitext(file)[0]\n",
    "            match = re.search(r\"\\d{4}\", basename)\n",
    "            year = match.group(0) if match else \"unknown\"\n",
    "            if year == \"unknown\":\n",
    "                raise ValueError(f\"No valid 4-digit year found in filename: {file}\")\n",
    "            table_name = f\"theme_blocks_{year}\".lower()\n",
    "\n",
    "            df = pd.read_excel(os.path.join(FOLDER, file))\n",
    "            df.columns = df.columns.str.strip()\n",
    "\n",
    "            col_types = {}\n",
    "            for col in df.columns:\n",
    "                if is_comment(col, df[col]):\n",
    "                    col_types[col] = \"comment\"\n",
    "                elif is_quantitative(df[col]):\n",
    "                    col_types[col] = \"quantitative\"\n",
    "                elif is_demographic(df[col]):\n",
    "                    col_types[col] = \"demographic\"\n",
    "                else:\n",
    "                    col_types[col] = \"unknown\"\n",
    "\n",
    "            cur.execute(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    respondent_index INT,\n",
    "                    year TEXT,\n",
    "                    demographics JSONB,\n",
    "                    questions JSONB,\n",
    "                    comment TEXT,\n",
    "                    sentiment JSONB\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "            for idx, row in df.iterrows():\n",
    "                respondent_index = int(idx) + 1\n",
    "                demographics = {\n",
    "                    col: str(row[col]).strip()\n",
    "                    for col in df.columns\n",
    "                    if col_types[col] == \"demographic\" and pd.notna(row[col]) and str(row[col]).strip() != \"\"\n",
    "                }\n",
    "\n",
    "                theme_blocks = []\n",
    "                current_questions = {}\n",
    "\n",
    "                for col in df.columns:\n",
    "                    value = row[col]\n",
    "                    col_type = col_types[col]\n",
    "\n",
    "                    if col_type == \"quantitative\":\n",
    "                        current_questions[col] = value\n",
    "                    elif col_type == \"comment\":\n",
    "                        sentiment_info = categorize_sentiment(value)\n",
    "                        theme_blocks.append({\n",
    "                            \"respondent_index\": respondent_index,\n",
    "                            \"year\": year,\n",
    "                            \"demographics\": clean_nan(dict(demographics)),\n",
    "                            \"questions\": clean_nan(dict(current_questions)),\n",
    "                            \"comment\": clean_nan(value),\n",
    "                            \"sentiment\": sentiment_info\n",
    "                        })\n",
    "                        current_questions = {}\n",
    "\n",
    "                if current_questions:\n",
    "                    theme_blocks.append({\n",
    "                        \"respondent_index\": respondent_index,\n",
    "                        \"year\": year,\n",
    "                        \"demographics\": clean_nan(dict(demographics)),\n",
    "                        \"questions\": clean_nan(current_questions),\n",
    "                        \"comment\": None,\n",
    "                        \"sentiment\": {\"label\": None, \"polarity\": None}\n",
    "                    })\n",
    "\n",
    "                for block in theme_blocks:\n",
    "                    cur.execute(f\"\"\"\n",
    "                        INSERT INTO {table_name} (\n",
    "                            respondent_index, year, demographics, questions, comment, sentiment\n",
    "                        ) VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        block[\"respondent_index\"],\n",
    "                        block[\"year\"],\n",
    "                        Json(block[\"demographics\"]),\n",
    "                        Json(block[\"questions\"]),\n",
    "                        block[\"comment\"],\n",
    "                        Json(block[\"sentiment\"])\n",
    "                    ))\n",
    "\n",
    "            print(f\" Inserted data into table: {table_name}\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()"
   ],
   "id": "a0c0da0afbf34cb5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:21.822814Z",
     "start_time": "2025-08-14T05:11:21.815950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def load_all_dataframes(db_name=\"thematic_yearly_survey\", user=\"postgres\", password=\"PUTOWNPASSWORD\", host=\"localhost\", port=\"5432\"):\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db_name,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        host=host,\n",
    "        port=port\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'public'\n",
    "        AND table_name LIKE 'theme_blocks_%';\n",
    "    \"\"\")\n",
    "    table_names = [row[0] for row in cur.fetchall()]\n",
    "\n",
    "    loaded_dataframes = {}\n",
    "\n",
    "    for table in table_names:\n",
    "        match = re.search(r'theme_blocks_(\\d{4})', table)\n",
    "        if match:\n",
    "            year = match.group(1)\n",
    "            df = pd.read_sql_query(f\"SELECT * FROM {table};\", conn)\n",
    "            var_name = f\"dataframe_{year}\"\n",
    "            loaded_dataframes[var_name] = df\n",
    "            print(f\" Loaded '{var_name}' with {len(df)} rows\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    loaded_dataframes['__names__'] = list(loaded_dataframes.keys())\n",
    "    return loaded_dataframes\n"
   ],
   "id": "e942bcedae34e6f6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# flatten data for sentiment polarity",
   "id": "d21936c4c11ec4c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:21.947799Z",
     "start_time": "2025-08-14T05:11:21.942320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_sentiment_fields(df, sentiment_col='sentiment', fields=None):\n",
    "\n",
    "    if fields is None:\n",
    "        fields = ['label', 'polarity']\n",
    "\n",
    "    for field in fields:\n",
    "        df[f\"{sentiment_col}_{field}\"] = df[sentiment_col].apply(\n",
    "            lambda x: x.get(field) if isinstance(x, dict) else None\n",
    "        )\n",
    "\n",
    "    return df\n"
   ],
   "id": "251f88362f7d3753",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### now  this is to create proper sentiment and polarity columns",
   "id": "99a5f176777714b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:22.017308Z",
     "start_time": "2025-08-14T05:11:22.009979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_and_rename_sentiment_fields(df_dict):\n",
    "    updated_count = 0\n",
    "\n",
    "    for name, df in df_dict.items():\n",
    "        modified = False\n",
    "\n",
    "        # Drop 'sentiment' column if it exists\n",
    "        if 'sentiment' in df.columns:\n",
    "            df.drop(columns=['sentiment'], inplace=True)\n",
    "            modified = True\n",
    "\n",
    "        # Rename 'sentiment_label' to 'sentiment' if not already renamed\n",
    "        if 'sentiment_label' in df.columns and 'sentiment' not in df.columns:\n",
    "            df.rename(columns={'sentiment_label': 'sentiment'}, inplace=True)\n",
    "            modified = True\n",
    "\n",
    "        if modified:\n",
    "            updated_count += 1\n",
    "            print(f\" Cleaned {name}\")\n",
    "\n",
    "    print(f\" Total cleaned DataFrames: {updated_count}\")\n",
    "    return updated_count\n",
    "#"
   ],
   "id": "9dce1aee6a55528c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:22.076398Z",
     "start_time": "2025-08-14T05:11:22.072605Z"
    }
   },
   "cell_type": "code",
   "source": "# open api key",
   "id": "637032c7375e0269",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:14:18.785878Z",
     "start_time": "2025-08-14T05:14:18.754947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "\n",
    "# Set API key\n",
    "client = openai.OpenAI(api_key=\"sk-\")  #\n",
    "\n"
   ],
   "id": "8c78eeacc41eb98f",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### extraction of demographic keys",
   "id": "5fec1c1f8471dd41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:23.383906Z",
     "start_time": "2025-08-14T05:11:23.377870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_unique_demographic_keys(df_dict, column_name=\"demographics\"):\n",
    "\n",
    "    def extract_keys(d):\n",
    "        return list(d.keys()) if isinstance(d, dict) else []\n",
    "\n",
    "    all_keys = []\n",
    "\n",
    "    for name, df in df_dict.items():\n",
    "        if column_name in df.columns:\n",
    "            nested_keys = df[column_name].apply(extract_keys)\n",
    "            flat_keys = [key for sublist in nested_keys for key in sublist]\n",
    "            all_keys.extend(flat_keys)\n",
    "            print(f\" Extracted keys from {name}\")\n",
    "\n",
    "    unique_keys = sorted(set(all_keys))\n",
    "    print(f\" demographic_keys = {unique_keys}\")\n",
    "    return unique_keys\n"
   ],
   "id": "46f16bd857dd51bb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### demographic prompt",
   "id": "48edd997d4161126"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:23.431901Z",
     "start_time": "2025-08-14T05:11:23.425226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_demographic_mapping_prompt(keys):\n",
    "\n",
    "    prompt = (\n",
    "    \"You are a schema normalization assistant. Given a list of demographic survey field names:\\n\\n\"\n",
    "    + \"\\n\".join(f\"- {key}\" for key in keys) +\n",
    "    \"\\n\\nYour task is to:\\n\"\n",
    "    \"1. Normalize each key into a canonical, consistent label.\\n\"\n",
    "    \"2. Avoid spelling-based confusion (e.g., 'Carer' ≠ 'Career').\\n\"\n",
    "    \"3. Where multiple keys refer to the same underlying concept (e.g., 'Ethnicity' and 'What is your ethnic background?'), unify them to the same canonical form.\\n\"\n",
    "    \"4. If a field is ambiguous like 'Are you?', treat it as 'Gender' only if options suggest that.\\n\\n\"\n",
    "    \"Return a Python dictionary in this format:\\n\"\n",
    "    \"{'Original Key': 'CleanedKey', ...}\"\n",
    "      )\n",
    "    return prompt\n"
   ],
   "id": "beadf857fc566384",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### get key mapping from llm",
   "id": "93265613c582e574"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:23.546272Z",
     "start_time": "2025-08-14T05:11:23.535270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pricing per 1K tokens (as of 2025-08, adjust if OpenAI updates)\n",
    "PRICING = {\n",
    "    \"gpt-4\":         {\"input\": 0.03,  \"output\": 0.06},  # $ per 1K tokens\n",
    "    \"gpt-4-turbo\":   {\"input\": 0.01,  \"output\": 0.03},  # Turbo is cheaper\n",
    "    \"gpt-3.5-turbo\": {\"input\": 0.001, \"output\": 0.002}\n",
    "}\n",
    "\n",
    "# Track totals for each model\n",
    "token_usage_summary = {\n",
    "    \"gpt-4\":         {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0},\n",
    "    \"gpt-4-turbo\":   {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0},\n",
    "    \"gpt-3.5-turbo\": {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0}\n",
    "}\n",
    "\n",
    "def get_cleaned_key_mapping(prompt, model_name=\"gpt-4\", temperature=0.4):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You help with standardizing dataset keys.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    # --- Record usage ---\n",
    "    usage = response.usage\n",
    "    input_tokens = usage.prompt_tokens\n",
    "    output_tokens = usage.completion_tokens\n",
    "\n",
    "    # Compute cost\n",
    "    price = PRICING.get(model_name, {\"input\": 0, \"output\": 0})\n",
    "    cost = (input_tokens / 1000 * price[\"input\"]) + (output_tokens / 1000 * price[\"output\"])\n",
    "\n",
    "    # Update totals\n",
    "    if model_name not in token_usage_summary:\n",
    "        token_usage_summary[model_name] = {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0}\n",
    "\n",
    "    token_usage_summary[model_name][\"input_tokens\"]  += input_tokens\n",
    "    token_usage_summary[model_name][\"output_tokens\"] += output_tokens\n",
    "    token_usage_summary[model_name][\"cost\"]          += cost\n",
    "\n",
    "    print(f\"[{model_name}] Input tokens: {input_tokens}, Output tokens: {output_tokens}, Cost: ${cost:.6f}\")\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def print_usage_summary():\n",
    "    print(\"\\n=== Token Usage Summary ===\")\n",
    "    for model, stats in token_usage_summary.items():\n",
    "        total_tokens = stats[\"input_tokens\"] + stats[\"output_tokens\"]\n",
    "        print(f\"{model}: {total_tokens} tokens \"\n",
    "              f\"(input={stats['input_tokens']}, output={stats['output_tokens']}), \"\n",
    "              f\"Total cost=${stats['cost']:.6f}\")\n"
   ],
   "id": "9538a2f580ca46e9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### clean the extra output from llm and ask user to chose the mapping ( optional )",
   "id": "a380cbf42e051226"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:24.665986Z",
     "start_time": "2025-08-14T05:11:24.655835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "# --- Core Parser ---\n",
    "def extract_first_dict_from_response(text, verbose=True):\n",
    "    \"\"\"\n",
    "    Extracts the first dictionary-like structure from an LLM response string.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        dict_text = match.group()\n",
    "        try:\n",
    "            result = ast.literal_eval(dict_text)\n",
    "            if verbose:\n",
    "                print(\" Successfully extracted dictionary.\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\" Failed to parse dictionary: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\" No dictionary block found in text.\")\n",
    "        return None\n",
    "\n",
    "# --- Selector ---\n",
    "def choose_llm_mapping(mapping_responses):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(\"\\n Available model responses:\")\n",
    "    options = list(mapping_responses.keys())\n",
    "    for i, model in enumerate(options, start=1):\n",
    "        print(f\"{i}. {model.upper()}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Select a model response to extract mapping from (1 or 2): \"))\n",
    "            if 1 <= choice <= len(options):\n",
    "                selected_model = options[choice - 1]\n",
    "                print(f\"\\n Extracting mapping from {selected_model.upper()} response...\\n\")\n",
    "                mapping_dict = extract_first_dict_from_response(mapping_responses[selected_model])\n",
    "                if mapping_dict is not None:\n",
    "                    print(\" Extracted Mapping:\\n\")\n",
    "                    for k, v in mapping_dict.items():\n",
    "                        print(f\"  {repr(k)}: {repr(v)}\")\n",
    "                return mapping_dict\n",
    "            else:\n",
    "                print(\" Invalid choice. Please enter 1 or 2.\")\n",
    "        except ValueError:\n",
    "            print(\" Please enter a number.\")\n"
   ],
   "id": "e6dc87d694140635",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### now apply mappings to data frames",
   "id": "ba0320eddb3027ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:25.761164Z",
     "start_time": "2025-08-14T05:11:25.752763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#  Key normalization function\n",
    "def normalize_demographic_keys(demo_dict, mapping):\n",
    "    if isinstance(demo_dict, dict):\n",
    "        return {\n",
    "            mapping.get(k.strip(), k.strip()): v\n",
    "            for k, v in demo_dict.items()\n",
    "        }\n",
    "    return demo_dict\n",
    "\n",
    "#  Apply demographic normalization to all unpacked_dfs and sync to globals\n",
    "def normalize_all_demographics(unpacked_dfs, mapping):\n",
    "    for name, df in unpacked_dfs.items():\n",
    "        if isinstance(df, pd.DataFrame) and \"demographics\" in df.columns:\n",
    "            df_normalized = df.copy()\n",
    "            df_normalized[\"demographics\"] = df_normalized[\"demographics\"].apply(\n",
    "                lambda d: normalize_demographic_keys(d, mapping)\n",
    "            )\n",
    "            unpacked_dfs[name] = df_normalized\n",
    "            globals()[name] = df_normalized  # sync with global variable too\n",
    "            print(f\" Normalized demographics for {name}\")\n",
    "\n",
    "\n",
    "\n",
    "#  Optional preview\n",
    "# unpacked_dfs[\"df_2023\"][\"demographics\"].dropna().head()\n"
   ],
   "id": "ce0416545d9de97c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "normalization of questions, full process",
   "id": "f6f42088fe36b7ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:51.504714Z",
     "start_time": "2025-08-14T05:11:51.481942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_question_keys(row):\n",
    "    \"\"\"Extract keys from a dictionary in the 'questions' column.\"\"\"\n",
    "    if isinstance(row, dict):\n",
    "        return list(row.keys())\n",
    "    return []\n",
    "\n",
    "def get_question_keys_from_dataframe(df: pd.DataFrame) -> list:\n",
    "    \"\"\"Extract all question keys from the 'questions' column of a DataFrame.\"\"\"\n",
    "    if \"questions\" not in df.columns:\n",
    "        return []\n",
    "    keys_series = df[\"questions\"].apply(extract_question_keys)\n",
    "    return [key for sublist in keys_series for key in sublist]\n",
    "\n",
    "def collect_question_keys_from_unpacked_dfs(unpacked_dfs: dict) -> list:\n",
    "    \"\"\"Scan unpacked DataFrames and extract question keys.\"\"\"\n",
    "    all_keys = []\n",
    "    for df_name, df in unpacked_dfs.items():\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            if \"questions\" in df.columns:\n",
    "                keys = get_question_keys_from_dataframe(df)\n",
    "                all_keys.extend(keys)\n",
    "                print(f\" Processed {df_name}\")\n",
    "    return sorted(set(all_keys))\n",
    "\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "# ---------- Pricing (per 1K tokens) – update to your rates ----------\n",
    "PRICING = {\n",
    "    \"gpt-4\":         {\"input\": 0.03,  \"output\": 0.06},\n",
    "    \"gpt-4-turbo\":   {\"input\": 0.01,  \"output\": 0.03},    # example\n",
    "    \"gpt-3.5-turbo\": {\"input\": 0.001, \"output\": 0.002},\n",
    "}\n",
    "\n",
    "# ---------- Running totals ----------\n",
    "token_usage_summary = {\n",
    "    m: {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0}\n",
    "    for m in PRICING.keys()\n",
    "}\n",
    "\n",
    "def _record_usage(model_name: str, usage) -> None:\n",
    "    \"\"\"Accumulate tokens & cost into token_usage_summary for a single response.\"\"\"\n",
    "    if usage is None:\n",
    "        return\n",
    "    input_tokens = getattr(usage, \"prompt_tokens\", None) or getattr(usage, \"prompt_tokens\", 0)\n",
    "    output_tokens = getattr(usage, \"completion_tokens\", None) or getattr(usage, \"completion_tokens\", 0)\n",
    "\n",
    "    price = PRICING.get(model_name, {\"input\": 0.0, \"output\": 0.0})\n",
    "    cost = (input_tokens / 1000.0) * price[\"input\"] + (output_tokens / 1000.0) * price[\"output\"]\n",
    "\n",
    "    bucket = token_usage_summary.setdefault(model_name, {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0})\n",
    "    bucket[\"input_tokens\"]  += input_tokens\n",
    "    bucket[\"output_tokens\"] += output_tokens\n",
    "    bucket[\"cost\"]          += cost\n",
    "\n",
    "    print(f\"[{model_name}] input={input_tokens}, output={output_tokens}, cost=${cost:.6f}\")\n",
    "\n",
    "\n",
    "# ---------- Your prompt builder (unchanged) ----------\n",
    "def build_question_normalization_prompt(question_keys: List[str]) -> str:\n",
    "    formatted_keys = \"\\n\".join(f\"- {key}\" for key in question_keys)\n",
    "    example_mapping = \"\"\"{\n",
    "    'Public transport': 'Public Transport',\n",
    "    'Public & Transport': 'Public Transport',\n",
    "    'Sense of Community 1': 'Sense of Community 1',\n",
    "    'Sense of Community 2': 'Sense of Community 2'\n",
    "}\"\"\"\n",
    "    return (\n",
    "        \"You are a data normalization assistant. Below is a list of survey question keys:\\n\\n\"\n",
    "        f\"{formatted_keys}\\n\\n\"\n",
    "        \"Your task is to return a Python dictionary that groups semantically similar phrases under one consistent label.\\n\"\n",
    "        \"However, preserve numeric suffixes where they appear to represent different items (e.g., 'Sense of Community 1', '... 2', etc.).\\n\"\n",
    "        \"Do not merge them into one label like 'Sense of Community'.\\n\"\n",
    "        \"Only group entries when they are true paraphrases of the same concept, not when they are distinct numbered items.\\n\\n\"\n",
    "        \"Return the result in valid Python dictionary format. For example:\\n\"\n",
    "        f\"{example_mapping}\\n\\n\"\n",
    "        \"Return only the dictionary — no explanations.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------- Updated model call with usage & cost tracking ----------\n",
    "def get_question_mapping_from_model(model_name: str, prompt: str) -> Dict[str, str]:\n",
    "    \"\"\"Calls an OpenAI model to get a question-key normalization mapping, and records token usage & cost.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You help clean and normalize field names in datasets.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    # record usage & cost\n",
    "    _record_usage(model_name, getattr(response, \"usage\", None))\n",
    "\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        mapping = ast.literal_eval(content)\n",
    "        assert isinstance(mapping, dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse response from {model_name}: {e}\")\n",
    "        mapping = {}\n",
    "    return mapping\n",
    "\n",
    "def normalize_question_keys_with_models(question_keys: List[str]) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"Builds the prompt and queries both GPT-4 and GPT-3.5 for normalization mappings.\"\"\"\n",
    "    prompt = build_question_normalization_prompt(question_keys)\n",
    "\n",
    "    gpt4_mapping = get_question_mapping_from_model(\"gpt-4\", prompt)\n",
    "    print(\"\\n GPT-4 Question Normalization Mapping:\\n\", gpt4_mapping)\n",
    "\n",
    "    gpt35_mapping = get_question_mapping_from_model(\"gpt-3.5-turbo\", prompt)\n",
    "    print(\"\\n GPT-3.5 Question Normalization Mapping:\\n\", gpt35_mapping)\n",
    "\n",
    "    gpt4_turbo_mapping = get_question_mapping_from_model(\"gpt-4-turbo\", prompt)\n",
    "    print(\"\\n GPT-4 turbo Question Normalization Mapping:\\n\", gpt4_turbo_mapping)\n",
    "    print_usage_summary()\n",
    "    return {\n",
    "        \"gpt-4\": gpt4_mapping,\n",
    "        \"gpt-3.5-turbo\": gpt35_mapping,\n",
    "        \"gpt-4-turbo\": gpt4_turbo_mapping\n",
    "\n",
    "    }\n",
    "\n",
    "def choose_question_key_mapping(mappings: dict) -> dict:\n",
    "    \"\"\"Display both GPT mappings and let the user choose one.\"\"\"\n",
    "    print(\"\\n GPT-4 Normalization Mapping:\\n\")\n",
    "    for k, v in mappings.get(\"gpt-4\", {}).items():\n",
    "        print(f\"{k!r}: {v!r}\")\n",
    "\n",
    "    print(\"\\n GPT-3.5 Normalization Mapping:\\n\")\n",
    "    for k, v in mappings.get(\"gpt-3.5-turbo\", {}).items():\n",
    "        print(f\"{k!r}: {v!r}\")\n",
    "\n",
    "    # Prompt user for selection\n",
    "    print(\"\\n Choose the mapping you want to apply:\")\n",
    "    print(\"1 → GPT-3.5\")\n",
    "    print(\"2 → GPT-4\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"Enter 1 or 2: \").strip()\n",
    "        if choice == \"1\":\n",
    "            print(\" Using GPT-3.5 mapping.\")\n",
    "            return mappings[\"gpt-3.5-turbo\"]\n",
    "        elif choice == \"2\":\n",
    "            print(\" Using GPT-4 mapping.\")\n",
    "            return mappings[\"gpt-4\"]\n",
    "        else:\n",
    "            print(\"️ Invalid input. Please enter 1 or 2.\")\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def parse_question_mapping(mapping_str: str) -> Dict[str, str]:\n",
    "    \"\"\"Safely parse a string containing a Python dictionary.\"\"\"\n",
    "    try:\n",
    "        mapping = ast.literal_eval(mapping_str)\n",
    "        assert isinstance(mapping, dict)\n",
    "        return mapping\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to parse mapping string: {e}\")\n",
    "        return {}\n",
    "\n",
    "def normalize_question_dict(q_dict: dict, mapping: dict) -> dict:\n",
    "    \"\"\"Normalize the keys in a single question dictionary using the mapping.\"\"\"\n",
    "    if isinstance(q_dict, dict):\n",
    "        return {\n",
    "            mapping.get(k.strip(), k.strip()): v\n",
    "            for k, v in q_dict.items()\n",
    "        }\n",
    "    return q_dict\n",
    "\n",
    "def apply_mapping_to_unpacked_dfs(unpacked_dfs: dict, mapping: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Apply a question key normalization mapping to all DataFrames in unpacked_dfs.\n",
    "    Returns a new dictionary of normalized DataFrames.\n",
    "    \"\"\"\n",
    "    normalized_dfs = {}\n",
    "    for name, df in unpacked_dfs.items():\n",
    "        if isinstance(df, pd.DataFrame) and \"questions\" in df.columns:\n",
    "            df_normalized = df.copy()\n",
    "            df_normalized[\"questions\"] = df[\"questions\"].apply(lambda q: normalize_question_dict(q, mapping))\n",
    "            normalized_dfs[name] = df_normalized\n",
    "            print(f\" Normalized questions for {name}\")\n",
    "        else:\n",
    "            normalized_dfs[name] = df  # preserve untouched if no 'questions' column\n",
    "    return normalized_dfs\n"
   ],
   "id": "d1b7d1d8d9a6effb",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "explode questions before macro theme",
   "id": "b6cafc82db0b32af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:53.875174Z",
     "start_time": "2025-08-14T05:11:53.866469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explode_questions_into_named_ratings(unpacked_dfs: dict, source_col: str = \"questions\") -> None:\n",
    "    \"\"\"\n",
    "    Explode 'questions' dict column in each DataFrame in unpacked_dfs.\n",
    "    Adds 'namedquestion' and 'rating' columns.\n",
    "    Updates unpacked_dfs in-place.\n",
    "    \"\"\"\n",
    "    for name, df in unpacked_dfs.items():\n",
    "        if isinstance(df, pd.DataFrame) and source_col in df.columns:\n",
    "            records = []\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                q_dict = row.get(source_col)\n",
    "                if isinstance(q_dict, dict):\n",
    "                    for k, v in q_dict.items():\n",
    "                        new_row = row.drop(labels=[source_col]).to_dict()\n",
    "                        new_row[\"question_label\"] = k\n",
    "                        new_row[\"rating_label\"] = v if isinstance(v, (int, float)) else None\n",
    "                        records.append(new_row)\n",
    "                else:\n",
    "                    new_row = row.to_dict()\n",
    "                    new_row[\"question_label\"] = None\n",
    "                    new_row[\"rating_label\"] = None\n",
    "                    records.append(new_row)\n",
    "\n",
    "            unpacked_dfs[name] = pd.DataFrame(records)\n",
    "            print(f\"Exploded and updated: {name}\")\n"
   ],
   "id": "b960995821dd84a7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "macro theme",
   "id": "ded01af9bafd33ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:11:55.381465Z",
     "start_time": "2025-08-14T05:11:55.371345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Macro theme mapping (unchanged)\n",
    "MACRO_THEME_MAP = {\n",
    "    \"Active Travel\": \"MOVEMENT\",\n",
    "    \"Public Transport\": \"MOVEMENT\",\n",
    "    \"Traffic & Parking\": \"MOVEMENT\",\n",
    "    \"Moving Around\": \"MOVEMENT\",\n",
    "\n",
    "    \"Streets & Spaces\": \"SPACE\",\n",
    "    \"Natural Space\": \"SPACE\",\n",
    "    \"Play & Recreation\": \"SPACE\",\n",
    "\n",
    "    \"Facilities & Amenities\": \"RESOURCES\",\n",
    "    \"Work & Local Economy\": \"RESOURCES\",\n",
    "    \"Housing & Community\": \"RESOURCES\",\n",
    "    \"Social Interactions\": \"RESOURCES\",\n",
    "\n",
    "    \"Identity & Belonging\": \"CIVIC\",\n",
    "    \"Feeling Safe\": \"CIVIC\",\n",
    "    \"Sense of Community\": \"CIVIC\",\n",
    "\n",
    "    \"Care & Maintenance\": \"STEWARDSHIP\",\n",
    "    \"Care & Maintenance Are buildings and spaces well cared for?\": \"STEWARDSHIP\",\n",
    "    \"Influence & Control\": \"STEWARDSHIP\"\n",
    "}\n",
    "\n",
    "\n",
    "#  Label assigner for namedquestion column\n",
    "def assign_macro_label_from_namedquestion(named_q: str, mapping: dict) -> str:\n",
    "    if isinstance(named_q, str):\n",
    "        return mapping.get(named_q.strip(), None)\n",
    "    return None\n",
    "\n",
    "#  Apply macro_label using namedquestion column across all unpacked_dfs\n",
    "def apply_macro_labels_from_namedquestion(unpacked_dfs: dict, macro_mapping: dict) -> None:\n",
    "    for name, df in unpacked_dfs.items():\n",
    "        if isinstance(df, pd.DataFrame) and \"question_label\" in df.columns:\n",
    "            df_labeled = df.copy()\n",
    "            df_labeled[\"macro_label\"] = df_labeled[\"question_label\"].apply(\n",
    "                lambda x: assign_macro_label_from_namedquestion(x, macro_mapping)\n",
    "            )\n",
    "            unpacked_dfs[name] = df_labeled\n",
    "            globals()[name] = df_labeled  # Sync back\n",
    "            print(f\" Added macro_label from question_label to {name}\")\n"
   ],
   "id": "27df54de19231a98",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "flatten demographics",
   "id": "e490fc1113accb35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:12:30.663170Z",
     "start_time": "2025-08-14T05:12:30.656112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def flatten_demographics_columns(dataframes: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Flatten the 'demographics' column (dicts) into top-level columns for all DataFrames.\n",
    "    Returns a new dictionary with keys as 'original_name_flat'.\n",
    "    Also updates globals for direct use in notebook.\n",
    "    \"\"\"\n",
    "    flattened = {}\n",
    "\n",
    "    for name, df in dataframes.items():\n",
    "        if isinstance(df, pd.DataFrame) and \"demographics\" in df.columns:\n",
    "            df_flat = pd.concat(\n",
    "                [df.drop(columns=[\"demographics\"]),\n",
    "                 df[\"demographics\"].apply(pd.Series)],\n",
    "                axis=1\n",
    "            )\n",
    "            flat_name = f\"{name}_flat\"\n",
    "            flattened[flat_name] = df_flat\n",
    "            globals()[flat_name] = df_flat  # store for interactive use\n",
    "            print(f\" Flattened demographics in {name} → stored as {flat_name}\")\n",
    "\n",
    "    return flattened\n",
    "\n"
   ],
   "id": "338129c8215aae4d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "data types rectification",
   "id": "c06caea50b10c95e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:12:32.892787Z",
     "start_time": "2025-08-14T05:12:32.882737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def infer_and_assign_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Infers and assigns optimal data types for each column in a DataFrame.\n",
    "    Converts numerics, datetimes, booleans, and low-cardinality strings to categories.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        inferred = pd.api.types.infer_dtype(df[col], skipna=True)\n",
    "\n",
    "        if inferred in ['integer', 'floating', 'mixed-integer-float']:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            except Exception:\n",
    "                pass\n",
    "        elif inferred in ['datetime', 'datetime64']:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            except Exception:\n",
    "                pass\n",
    "        elif inferred == 'boolean':\n",
    "            df[col] = df[col].astype('boolean')\n",
    "        elif inferred in ['string', 'unicode']:\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            if len(unique_vals) < len(df) * 0.1:  # treat low-cardinality strings as categories\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    return df.convert_dtypes()\n",
    "\n",
    "def apply_type_inference_to_unpacked_dfs(unpacked_dfs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Applies dtype inference and optimization to all DataFrames in unpacked_dfs.\n",
    "    Updates the original unpacked_dfs dictionary in-place and returns it.\n",
    "    \"\"\"\n",
    "    for name, df in unpacked_dfs.items():\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            inferred_df = infer_and_assign_dtypes(df)\n",
    "            unpacked_dfs[name] = inferred_df\n",
    "            print(f\" Inferred dtypes for {name}\")\n",
    "    return unpacked_dfs\n"
   ],
   "id": "8f86d84188de1c70",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:24:12.012417Z",
     "start_time": "2025-08-14T05:24:11.996488Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 37,
   "source": "",
   "id": "9488a714aa58e7f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:25:30.976206Z",
     "start_time": "2025-08-14T05:25:30.966178Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58977bf764c34d07",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### postgres ingestion final",
   "id": "3e26e446a3945c9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def insert_all_flat_dataframes(unpacked_dfs, db_name, user, password, host, port):\n",
    "    # Create PostgreSQL connection string\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db_name}\")\n",
    "\n",
    "    for idx, (df_name, df) in enumerate(unpacked_dfs.items(), start=1):\n",
    "        table_name = f\"{df_name}_{idx}\"  # e.g., survey_1, survey_2\n",
    "        print(f\"Inserting DataFrame into table: {table_name}\")\n",
    "\n",
    "        # Write DataFrame to PostgreSQL\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "    print(\" All DataFrames inserted successfully!\")\n"
   ],
   "id": "526ebb0acb7f73d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pipeline begins",
   "id": "3c95e81b0ba0eaa8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "main"
   ],
   "id": "94e69eb31de43f40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:13:10.706579Z",
     "start_time": "2025-08-14T05:12:52.605008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "create_database()\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "ingest_excel_to_postgres() # or ingest_excel_to_mongodb()\n",
    "print(\"Ingestion Time:\", time.time() - start, \"seconds\")\n",
    "start = time.time()\n",
    "start = time.time()\n",
    "dfs = load_all_dataframes()\n",
    "print(\"loading Time:\", time.time() - start, \"seconds\")\n"
   ],
   "id": "55e60f45bb8723b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Database already exists.\n",
      "\n",
      " Processing file: 2016_Our_Place_Results_Redacted.xlsx\n",
      " Inserted data into table: theme_blocks_2016\n",
      "\n",
      " Processing file: Place Survey 2018 Data_Redacted.xlsx\n",
      " Inserted data into table: theme_blocks_2018\n",
      "\n",
      " Processing file: Place Survey 2020 Data_Redacted.xlsx\n",
      " Inserted data into table: theme_blocks_2020\n",
      "\n",
      " Processing file: SurveyResults-Our_Place_2023_ORIGINAL (1).xlsx\n",
      " Inserted data into table: theme_blocks_2023\n",
      "Ingestion Time: 18.033456325531006 seconds\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:13:26.813573Z",
     "start_time": "2025-08-14T05:13:25.901856Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9023dbee5272fa51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ltopuser\\AppData\\Local\\Temp\\ipykernel_17432\\3697741667.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(f\"SELECT * FROM {table};\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 'dataframe_2023' with 6340 rows\n",
      " Loaded 'dataframe_2020' with 6015 rows\n",
      " Loaded 'dataframe_2016' with 13695 rows\n",
      " Loaded 'dataframe_2018' with 3735 rows\n",
      "loading Time: 0.9067165851593018 seconds\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:13:33.398403Z",
     "start_time": "2025-08-14T05:13:32.364197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "#  Run the function\n",
    "\n",
    "dfs = load_all_dataframes()\n",
    "\n",
    "unpacked_dfs = {}\n",
    "\n",
    "for key, df in dfs.items():\n",
    "    if key.startswith(\"dataframe_\"):\n",
    "        year = key.split(\"_\")[1]\n",
    "        var_name = f\"df_{year}\"\n",
    "        locals()[var_name] = df\n",
    "        unpacked_dfs[var_name] = df  #  Add this\n",
    "        print(f\"Created variable {var_name} with {len(df)} rows\")\n",
    "\n",
    "\n",
    "for name, df in unpacked_dfs.items():\n",
    "    extract_sentiment_fields(df)\n",
    "    print(f\" Updated {name}\")\n",
    "\n",
    "# Call the function and pass in your unpacked_dfs dictionary\n",
    "clean_and_rename_sentiment_fields(unpacked_dfs)\n",
    "\n",
    "\n",
    "unique_demographic_keys = extract_unique_demographic_keys(unpacked_dfs)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "bb776bbf1ec5a548",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ltopuser\\AppData\\Local\\Temp\\ipykernel_17432\\3697741667.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(f\"SELECT * FROM {table};\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 'dataframe_2023' with 6340 rows\n",
      " Loaded 'dataframe_2020' with 6015 rows\n",
      " Loaded 'dataframe_2016' with 13695 rows\n",
      " Loaded 'dataframe_2018' with 3735 rows\n",
      "Created variable df_2023 with 6340 rows\n",
      "Created variable df_2020 with 6015 rows\n",
      "Created variable df_2016 with 13695 rows\n",
      "Created variable df_2018 with 3735 rows\n",
      " Updated df_2023\n",
      " Updated df_2020\n",
      " Updated df_2016\n",
      " Updated df_2018\n",
      " Cleaned df_2023\n",
      " Cleaned df_2020\n",
      " Cleaned df_2016\n",
      " Cleaned df_2018\n",
      " Total cleaned DataFrames: 4\n",
      " Extracted keys from df_2023\n",
      " Extracted keys from df_2020\n",
      " Extracted keys from df_2016\n",
      " Extracted keys from df_2018\n",
      " demographic_keys = ['Age', 'Are you?', 'Care for a family member /friend?', 'Carer', 'Disabled', 'Do you care for a family member/friend because of their illness or disability?', 'Do you care for a family member/friend?', 'Do you consider yourself disabled?', 'Do you consider yourself to be disabled?', 'Do you have a hearing impairment?', 'Do you have a visual impairment?', 'Do you have non-dependent children living with you?', 'Do you have pre-school children living with you?', 'Do you have pre-school children?', 'Do you have preschool children living with you?', 'Do you have problems with mobility?', 'Do you have school-age children living with you?', 'Do you have school-age children?', 'Do you have schoolage children living with you?', 'Do you use a wheelchair outdoors?', 'Ethnicity', 'Gender', 'House type', 'Housing status', 'Housing_status', 'Postcode', 'Pre-school children', 'School-age children', 'Source', 'What is your ethnic background?', 'Which age group are you in?']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:13:42.318105Z",
     "start_time": "2025-08-14T05:13:42.310752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_usage_summary():\n",
    "    print(\"\\n=== Token Usage Summary ===\")\n",
    "    for model, data in token_usage_summary.items():\n",
    "        total_tokens = data[\"input_tokens\"] + data[\"output_tokens\"]\n",
    "        print(f\"{model}:\")\n",
    "        print(f\"  Input tokens: {data['input_tokens']}\")\n",
    "        print(f\"  Output tokens: {data['output_tokens']}\")\n",
    "        print(f\"  Total tokens: {total_tokens}\")\n",
    "        print(f\"  Total cost: ${data['cost']:.6f}\")\n"
   ],
   "id": "24788cbafe44a6fb",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:15:29.333608Z",
     "start_time": "2025-08-14T05:14:53.981094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Generate prompt\n",
    "prompt = generate_demographic_mapping_prompt(unique_demographic_keys)\n",
    "\n",
    "# Step 2: Collect responses (now includes GPT-4 Turbo)\n",
    "mapping_responses = {\n",
    "    \"gpt-4\":       get_cleaned_key_mapping(prompt, model_name=\"gpt-4\"),\n",
    "    \"gpt-4-turbo\": get_cleaned_key_mapping(prompt, model_name=\"gpt-4-turbo\"),\n",
    "    \"gpt-3.5\":     get_cleaned_key_mapping(prompt, model_name=\"gpt-3.5-turbo\")\n",
    "}\n",
    "\n",
    "# Step 3: Preview responses\n",
    "for model, response in mapping_responses.items():\n",
    "    print(f\"\\n{model.upper()} Mapping Suggestion:\\n\")\n",
    "    print(response)\n",
    "\n",
    "# Step 4: Print usage and cost summary\n",
    "print_usage_summary()\n"
   ],
   "id": "7f5a1fb601f3c8f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4] Input tokens: 370, Output tokens: 458, Cost: $0.038580\n",
      "[gpt-4-turbo] Input tokens: 370, Output tokens: 488, Cost: $0.018340\n",
      "[gpt-3.5-turbo] Input tokens: 370, Output tokens: 441, Cost: $0.001252\n",
      "\n",
      "GPT-4 Mapping Suggestion:\n",
      "\n",
      "{\n",
      "    'Age': 'Age',\n",
      "    'Are you?': 'Gender',\n",
      "    'Care for a family member /friend?': 'CaringForFamilyOrFriend',\n",
      "    'Carer': 'Carer',\n",
      "    'Disabled': 'DisabilityStatus',\n",
      "    'Do you care for a family member/friend because of their illness or disability?': 'CaringForFamilyOrFriendDueToIllnessOrDisability',\n",
      "    'Do you care for a family member/friend?': 'CaringForFamilyOrFriend',\n",
      "    'Do you consider yourself disabled?': 'SelfIdentifiedDisability',\n",
      "    'Do you consider yourself to be disabled?': 'SelfIdentifiedDisability',\n",
      "    'Do you have a hearing impairment?': 'HearingImpairment',\n",
      "    'Do you have a visual impairment?': 'VisualImpairment',\n",
      "    'Do you have non-dependent children living with you?': 'NonDependentChildrenLivingAtHome',\n",
      "    'Do you have pre-school children living with you?': 'PreSchoolChildrenLivingAtHome',\n",
      "    'Do you have pre-school children?': 'PreSchoolChildren',\n",
      "    'Do you have preschool children living with you?': 'PreSchoolChildrenLivingAtHome',\n",
      "    'Do you have problems with mobility?': 'MobilityIssues',\n",
      "    'Do you have school-age children living with you?': 'SchoolAgeChildrenLivingAtHome',\n",
      "    'Do you have school-age children?': 'SchoolAgeChildren',\n",
      "    'Do you have schoolage children living with you?': 'SchoolAgeChildrenLivingAtHome',\n",
      "    'Do you use a wheelchair outdoors?': 'OutdoorWheelchairUse',\n",
      "    'Ethnicity': 'Ethnicity',\n",
      "    'Gender': 'Gender',\n",
      "    'House type': 'HouseType',\n",
      "    'Housing status': 'HousingStatus',\n",
      "    'Housing_status': 'HousingStatus',\n",
      "    'Postcode': 'Postcode',\n",
      "    'Pre-school children': 'PreSchoolChildren',\n",
      "    'School-age children': 'SchoolAgeChildren',\n",
      "    'Source': 'Source',\n",
      "    'What is your ethnic background?': 'Ethnicity',\n",
      "    'Which age group are you in?': 'AgeGroup'\n",
      "}\n",
      "\n",
      "GPT-4-TURBO Mapping Suggestion:\n",
      "\n",
      "Here's the normalized dictionary for the provided demographic survey field names:\n",
      "\n",
      "```python\n",
      "normalized_keys = {\n",
      "    'Age': 'Age',\n",
      "    'Are you?': 'Gender',  # Assuming this refers to gender based on common survey practices\n",
      "    'Care for a family member /friend?': 'CarerStatus',\n",
      "    'Carer': 'CarerStatus',\n",
      "    'Disabled': 'DisabilityStatus',\n",
      "    'Do you care for a family member/friend because of their illness or disability?': 'CarerStatus',\n",
      "    'Do you care for a family member/friend?': 'CarerStatus',\n",
      "    'Do you consider yourself disabled?': 'DisabilityStatus',\n",
      "    'Do you consider yourself to be disabled?': 'DisabilityStatus',\n",
      "    'Do you have a hearing impairment?': 'HearingImpairment',\n",
      "    'Do you have a visual impairment?': 'VisualImpairment',\n",
      "    'Do you have non-dependent children living with you?': 'NonDependentChildren',\n",
      "    'Do you have pre-school children living with you?': 'PreSchoolChildren',\n",
      "    'Do you have pre-school children?': 'PreSchoolChildren',\n",
      "    'Do you have preschool children living with you?': 'PreSchoolChildren',\n",
      "    'Do you have problems with mobility?': 'MobilityIssues',\n",
      "    'Do you have school-age children living with you?': 'SchoolAgeChildren',\n",
      "    'Do you have school-age children?': 'SchoolAgeChildren',\n",
      "    'Do you have schoolage children living with you?': 'SchoolAgeChildren',\n",
      "    'Do you use a wheelchair outdoors?': 'OutdoorWheelchairUse',\n",
      "    'Ethnicity': 'Ethnicity',\n",
      "    'Gender': 'Gender',\n",
      "    'House type': 'HouseType',\n",
      "    'Housing status': 'HousingStatus',\n",
      "    'Housing_status': 'HousingStatus',\n",
      "    'Postcode': 'Postcode',\n",
      "    'Pre-school children': 'PreSchoolChildren',\n",
      "    'School-age children': 'SchoolAgeChildren',\n",
      "    'Source': 'Source',\n",
      "    'What is your ethnic background?': 'Ethnicity',\n",
      "    'Which age group are you in?': 'AgeGroup'\n",
      "}\n",
      "```\n",
      "\n",
      "This dictionary maps the original field names to a standardized key, ensuring consistency and clarity across similar concepts, and grouping similar fields under a single canonical label.\n",
      "\n",
      "GPT-3.5 Mapping Suggestion:\n",
      "\n",
      "{\n",
      "    'Age': 'Age',\n",
      "    'Are you?': 'Gender',\n",
      "    'Care for a family member /friend?': 'Caregiver',\n",
      "    'Carer': 'Caregiver',\n",
      "    'Disabled': 'Disabled',\n",
      "    'Do you care for a family member/friend because of their illness or disability?': 'Caregiver_Reason',\n",
      "    'Do you care for a family member/friend?': 'Caregiver',\n",
      "    'Do you consider yourself disabled?': 'Disabled',\n",
      "    'Do you consider yourself to be disabled?': 'Disabled',\n",
      "    'Do you have a hearing impairment?': 'Hearing_Impairment',\n",
      "    'Do you have a visual impairment?': 'Visual_Impairment',\n",
      "    'Do you have non-dependent children living with you?': 'NonDependent_Children',\n",
      "    'Do you have pre-school children living with you?': 'PreSchool_Children',\n",
      "    'Do you have pre-school children?': 'PreSchool_Children',\n",
      "    'Do you have preschool children living with you?': 'PreSchool_Children',\n",
      "    'Do you have problems with mobility?': 'Mobility_Problems',\n",
      "    'Do you have school-age children living with you?': 'SchoolAge_Children',\n",
      "    'Do you have school-age children?': 'SchoolAge_Children',\n",
      "    'Do you have schoolage children living with you?': 'SchoolAge_Children',\n",
      "    'Do you use a wheelchair outdoors?': 'Wheelchair_Outdoors',\n",
      "    'Ethnicity': 'Ethnicity',\n",
      "    'Gender': 'Gender',\n",
      "    'House type': 'House_Type',\n",
      "    'Housing status': 'Housing_Status',\n",
      "    'Housing_status': 'Housing_Status',\n",
      "    'Postcode': 'Postcode',\n",
      "    'Pre-school children': 'PreSchool_Children',\n",
      "    'School-age children': 'SchoolAge_Children',\n",
      "    'Source': 'Source',\n",
      "    'What is your ethnic background?': 'Ethnicity',\n",
      "    'Which age group are you in?': 'Age_Group'\n",
      "}\n",
      "\n",
      "=== Token Usage Summary ===\n",
      "gpt-4:\n",
      "  Input tokens: 370\n",
      "  Output tokens: 458\n",
      "  Total tokens: 828\n",
      "  Total cost: $0.038580\n",
      "gpt-4-turbo:\n",
      "  Input tokens: 370\n",
      "  Output tokens: 488\n",
      "  Total tokens: 858\n",
      "  Total cost: $0.018340\n",
      "gpt-3.5-turbo:\n",
      "  Input tokens: 370\n",
      "  Output tokens: 441\n",
      "  Total tokens: 811\n",
      "  Total cost: $0.001252\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:22:00.740423Z",
     "start_time": "2025-08-14T05:15:29.395276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Let user choose and extract mapping\n",
    "demographic_key_mapping = choose_llm_mapping(mapping_responses)\n",
    "normalize_all_demographics(unpacked_dfs, demographic_key_mapping)"
   ],
   "id": "416a89fc8d9833c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Available model responses:\n",
      "1. GPT-4\n",
      "2. GPT-4-TURBO\n",
      "3. GPT-3.5\n",
      "\n",
      " Extracting mapping from GPT-4 response...\n",
      "\n",
      " Successfully extracted dictionary.\n",
      " Extracted Mapping:\n",
      "\n",
      "  'Age': 'Age'\n",
      "  'Are you?': 'Gender'\n",
      "  'Care for a family member /friend?': 'CaringForFamilyOrFriend'\n",
      "  'Carer': 'Carer'\n",
      "  'Disabled': 'DisabilityStatus'\n",
      "  'Do you care for a family member/friend because of their illness or disability?': 'CaringForFamilyOrFriendDueToIllnessOrDisability'\n",
      "  'Do you care for a family member/friend?': 'CaringForFamilyOrFriend'\n",
      "  'Do you consider yourself disabled?': 'SelfIdentifiedDisability'\n",
      "  'Do you consider yourself to be disabled?': 'SelfIdentifiedDisability'\n",
      "  'Do you have a hearing impairment?': 'HearingImpairment'\n",
      "  'Do you have a visual impairment?': 'VisualImpairment'\n",
      "  'Do you have non-dependent children living with you?': 'NonDependentChildrenLivingAtHome'\n",
      "  'Do you have pre-school children living with you?': 'PreSchoolChildrenLivingAtHome'\n",
      "  'Do you have pre-school children?': 'PreSchoolChildren'\n",
      "  'Do you have preschool children living with you?': 'PreSchoolChildrenLivingAtHome'\n",
      "  'Do you have problems with mobility?': 'MobilityIssues'\n",
      "  'Do you have school-age children living with you?': 'SchoolAgeChildrenLivingAtHome'\n",
      "  'Do you have school-age children?': 'SchoolAgeChildren'\n",
      "  'Do you have schoolage children living with you?': 'SchoolAgeChildrenLivingAtHome'\n",
      "  'Do you use a wheelchair outdoors?': 'OutdoorWheelchairUse'\n",
      "  'Ethnicity': 'Ethnicity'\n",
      "  'Gender': 'Gender'\n",
      "  'House type': 'HouseType'\n",
      "  'Housing status': 'HousingStatus'\n",
      "  'Housing_status': 'HousingStatus'\n",
      "  'Postcode': 'Postcode'\n",
      "  'Pre-school children': 'PreSchoolChildren'\n",
      "  'School-age children': 'SchoolAgeChildren'\n",
      "  'Source': 'Source'\n",
      "  'What is your ethnic background?': 'Ethnicity'\n",
      "  'Which age group are you in?': 'AgeGroup'\n",
      " Normalized demographics for df_2023\n",
      " Normalized demographics for df_2020\n",
      " Normalized demographics for df_2016\n",
      " Normalized demographics for df_2018\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:22:43.236608Z",
     "start_time": "2025-08-14T05:22:02.960385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Extract keys\n",
    "question_keys = collect_question_keys_from_unpacked_dfs(unpacked_dfs)\n",
    "\n",
    "# 2. Get normalization from both models\n",
    "mappings = normalize_question_keys_with_models(question_keys)\n",
    "\n"
   ],
   "id": "13791dc71ca227d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed df_2023\n",
      " Processed df_2020\n",
      " Processed df_2016\n",
      " Processed df_2018\n",
      "[gpt-4] input=647, output=841, cost=$0.069870\n",
      "\n",
      " GPT-4 Question Normalization Mapping:\n",
      " {'Active Travel': 'Active Travel', 'Care  Maintenance': 'Care & Maintenance', 'Care & Maintenance': 'Care & Maintenance', 'Are buildings and spaces well cared for?': 'Care & Maintenance', 'Care and maintenance': 'Care & Maintenance', 'Care__Maintenance_Are_buildings_and_spaces_well_cared_for?': 'Care & Maintenance', 'Facilities  Amenities': 'Facilities & Amenities', 'Facilities & Services': 'Facilities & Amenities', 'Facilities and amenities': 'Facilities & Amenities', 'Facilities__Amenities_Do_facilities_and_amenities_meet_my_needs?': 'Facilities & Amenities', 'Feeling Safe': 'Feeling Safe', 'Feeling safe': 'Feeling Safe', 'Housing  Community': 'Housing & Community', 'Housing & Community': 'Housing & Community', 'Housing and community': 'Housing & Community', 'Housing__Community_Does_housing_support_the_needs_of_the_community_and_contribute_to_a_positive_environment?': 'Housing & Community', 'Identity & Belonging': 'Identity & Belonging', 'Identity and belonging': 'Identity & Belonging', 'Influence & Control': 'Influence & Control', 'Do I feel able to participate in decisions and help change things for the better?': 'Influence & Control', 'Influence & Sense of Control': 'Influence & Control', 'Influence and sense of control': 'Influence & Control', 'Moving Around': 'Moving Around', 'Moving around': 'Moving Around', 'Moving_Around_Can_I_easily_walk_and_cycle_around_using_good_quality_routes?': 'Moving Around', 'Natural Space': 'Natural Space', 'Natural space': 'Natural Space', 'Natural_Space_Can_I_regularly_experience_good_quality_natural_space?': 'Natural Space', 'Play  Recreation': 'Play & Recreation', 'Play & Recreation': 'Play & Recreation', 'Play and recreation': 'Play & Recreation', 'Play__Recreation_Do_I_have_access_to_a_range_of_space_and_opportunities_for_play_and_recreation?': 'Play & Recreation', 'Public Transport': 'Public Transport', 'Public transport': 'Public Transport', 'Public_Transport_Does_public_transport_meet_my_needs?': 'Public Transport', 'Sense of community 1': 'Sense of Community 1', 'Sense of community 2': 'Sense of Community 2', 'Sense of community 3': 'Sense of Community 3', 'Sense of community 4': 'Sense of Community 4', 'Social Interaction': 'Social Interaction', 'Social Interactions': 'Social Interaction', 'Social interaction': 'Social Interaction', 'Streets  Spaces': 'Streets & Spaces', 'Streets & Spaces': 'Streets & Spaces', 'Streets and spaces': 'Streets & Spaces', 'Streets__Spaces_Do_buildings_streets_and_public_spaces__create_an_attractive_place_that_is_easy__to_get_around?': 'Streets & Spaces', 'Traffic  Parking': 'Traffic & Parking', 'Traffic & Parking': 'Traffic & Parking', 'Traffic and parking': 'Traffic & Parking', 'Traffic__Parking_Do_traffic_and_parking_arrangements_allow_people_to_move_around_safely_and_meet__the_communitys_needs?': 'Traffic & Parking', 'Work  Local Economy': 'Work & Local Economy', 'Work & Economy': 'Work & Local Economy', 'Work and local economy': 'Work & Local Economy', 'Work__Local_Economy_Is_there_an_active_local_economy_and_the_opportunity_to_access_good_quality_work?': 'Work & Local Economy'}\n",
      "[gpt-3.5-turbo] input=647, output=228, cost=$0.001103\n",
      "\n",
      " GPT-3.5 Question Normalization Mapping:\n",
      " {'Active Travel': 'Active Travel', 'Care Maintenance': 'Care & Maintenance', 'Facilities Amenities': 'Facilities & Amenities', 'Feeling Safe': 'Feeling Safe', 'Housing Community': 'Housing & Community', 'Identity & Belonging': 'Identity & Belonging', 'Influence & Control': 'Influence & Control', 'Moving Around': 'Moving Around', 'Natural Space': 'Natural Space', 'Play Recreation': 'Play & Recreation', 'Public Transport': 'Public Transport', 'Sense of community 1': 'Sense of community 1', 'Sense of community 2': 'Sense of community 2', 'Sense of community 3': 'Sense of community 3', 'Sense of community 4': 'Sense of community 4', 'Social Interaction': 'Social Interaction', 'Streets Spaces': 'Streets & Spaces', 'Traffic Parking': 'Traffic & Parking', 'Work Local Economy': 'Work & Local Economy'}\n",
      "[gpt-4-turbo] input=647, output=849, cost=$0.031940\n",
      "\n",
      " GPT-4 turbo Question Normalization Mapping:\n",
      " {'Active Travel': 'Active Travel', 'Care  Maintenance': 'Care and Maintenance', 'Care & Maintenance': 'Care and Maintenance', 'Are buildings and spaces well cared for?': 'Care and Maintenance', 'Care and maintenance': 'Care and Maintenance', 'Care__Maintenance_Are_buildings_and_spaces_well_cared_for?': 'Care and Maintenance', 'Facilities  Amenities': 'Facilities and Amenities', 'Facilities & Services': 'Facilities and Amenities', 'Facilities and amenities': 'Facilities and Amenities', 'Facilities__Amenities_Do_facilities_and_amenities_meet_my_needs?': 'Facilities and Amenities', 'Feeling Safe': 'Feeling Safe', 'Feeling safe': 'Feeling Safe', 'Housing  Community': 'Housing and Community', 'Housing & Community': 'Housing and Community', 'Housing and community': 'Housing and Community', 'Housing__Community_Does_housing_support_the_needs_of_the_community_and_contribute_to_a_positive_environment?': 'Housing and Community', 'Identity & Belonging': 'Identity and Belonging', 'Identity and belonging': 'Identity and Belonging', 'Influence & Control': 'Influence and Sense of Control', 'Do I feel able to participate in decisions and help change things for the better?': 'Influence and Sense of Control', 'Influence & Sense of Control': 'Influence and Sense of Control', 'Influence and sense of control': 'Influence and Sense of Control', 'Moving Around': 'Moving Around', 'Moving around': 'Moving Around', 'Moving_Around_Can_I_easily_walk_and_cycle_around_using_good_quality_routes?': 'Moving Around', 'Natural Space': 'Natural Space', 'Natural space': 'Natural Space', 'Natural_Space_Can_I_regularly_experience_good_quality_natural_space?': 'Natural Space', 'Play  Recreation': 'Play and Recreation', 'Play & Recreation': 'Play and Recreation', 'Play and recreation': 'Play and Recreation', 'Play__Recreation_Do_I_have_access_to_a_range_of_space_and_opportunities_for_play_and_recreation?': 'Play and Recreation', 'Public Transport': 'Public Transport', 'Public transport': 'Public Transport', 'Public_Transport_Does_public_transport_meet_my_needs?': 'Public Transport', 'Sense of community 1': 'Sense of Community 1', 'Sense of community 2': 'Sense of Community 2', 'Sense of community 3': 'Sense of Community 3', 'Sense of community 4': 'Sense of Community 4', 'Social Interaction': 'Social Interaction', 'Social Interactions': 'Social Interaction', 'Social interaction': 'Social Interaction', 'Streets  Spaces': 'Streets and Spaces', 'Streets & Spaces': 'Streets and Spaces', 'Streets and spaces': 'Streets and Spaces', 'Streets__Spaces_Do_buildings_streets_and_public_spaces__create_an_attractive_place_that_is_easy__to_get_around?': 'Streets and Spaces', 'Traffic  Parking': 'Traffic and Parking', 'Traffic & Parking': 'Traffic and Parking', 'Traffic and parking': 'Traffic and Parking', 'Traffic__Parking_Do_traffic_and_parking_arrangements_allow_people_to_move_around_safely_and_meet__the_communitys_needs?': 'Traffic and Parking', 'Work  Local Economy': 'Work and Local Economy', 'Work & Economy': 'Work and Local Economy', 'Work and local economy': 'Work and Local Economy', 'Work__Local_Economy_Is_there_an_active_local_economy_and_the_opportunity_to_access_good_quality_work?': 'Work and Local Economy'}\n",
      "\n",
      "=== Token Usage Summary ===\n",
      "gpt-4:\n",
      "  Input tokens: 1017\n",
      "  Output tokens: 1299\n",
      "  Total tokens: 2316\n",
      "  Total cost: $0.108450\n",
      "gpt-4-turbo:\n",
      "  Input tokens: 1017\n",
      "  Output tokens: 1337\n",
      "  Total tokens: 2354\n",
      "  Total cost: $0.050280\n",
      "gpt-3.5-turbo:\n",
      "  Input tokens: 1017\n",
      "  Output tokens: 669\n",
      "  Total tokens: 1686\n",
      "  Total cost: $0.002355\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:23:01.025007Z",
     "start_time": "2025-08-14T05:22:58.598305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Let user choose which mapping to apply\n",
    "selected_mapping = choose_question_key_mapping(mappings)\n",
    "\n",
    "#  Apply selected mapping to all unpacked DataFrames\n",
    "normalized_dfs = apply_mapping_to_unpacked_dfs(unpacked_dfs, selected_mapping)\n",
    "unpacked_dfs = normalized_dfs  # Update canonical dict"
   ],
   "id": "f06c8024b540f64b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GPT-4 Normalization Mapping:\n",
      "\n",
      "'Active Travel': 'Active Travel'\n",
      "'Care  Maintenance': 'Care & Maintenance'\n",
      "'Care & Maintenance': 'Care & Maintenance'\n",
      "'Are buildings and spaces well cared for?': 'Care & Maintenance'\n",
      "'Care and maintenance': 'Care & Maintenance'\n",
      "'Care__Maintenance_Are_buildings_and_spaces_well_cared_for?': 'Care & Maintenance'\n",
      "'Facilities  Amenities': 'Facilities & Amenities'\n",
      "'Facilities & Services': 'Facilities & Amenities'\n",
      "'Facilities and amenities': 'Facilities & Amenities'\n",
      "'Facilities__Amenities_Do_facilities_and_amenities_meet_my_needs?': 'Facilities & Amenities'\n",
      "'Feeling Safe': 'Feeling Safe'\n",
      "'Feeling safe': 'Feeling Safe'\n",
      "'Housing  Community': 'Housing & Community'\n",
      "'Housing & Community': 'Housing & Community'\n",
      "'Housing and community': 'Housing & Community'\n",
      "'Housing__Community_Does_housing_support_the_needs_of_the_community_and_contribute_to_a_positive_environment?': 'Housing & Community'\n",
      "'Identity & Belonging': 'Identity & Belonging'\n",
      "'Identity and belonging': 'Identity & Belonging'\n",
      "'Influence & Control': 'Influence & Control'\n",
      "'Do I feel able to participate in decisions and help change things for the better?': 'Influence & Control'\n",
      "'Influence & Sense of Control': 'Influence & Control'\n",
      "'Influence and sense of control': 'Influence & Control'\n",
      "'Moving Around': 'Moving Around'\n",
      "'Moving around': 'Moving Around'\n",
      "'Moving_Around_Can_I_easily_walk_and_cycle_around_using_good_quality_routes?': 'Moving Around'\n",
      "'Natural Space': 'Natural Space'\n",
      "'Natural space': 'Natural Space'\n",
      "'Natural_Space_Can_I_regularly_experience_good_quality_natural_space?': 'Natural Space'\n",
      "'Play  Recreation': 'Play & Recreation'\n",
      "'Play & Recreation': 'Play & Recreation'\n",
      "'Play and recreation': 'Play & Recreation'\n",
      "'Play__Recreation_Do_I_have_access_to_a_range_of_space_and_opportunities_for_play_and_recreation?': 'Play & Recreation'\n",
      "'Public Transport': 'Public Transport'\n",
      "'Public transport': 'Public Transport'\n",
      "'Public_Transport_Does_public_transport_meet_my_needs?': 'Public Transport'\n",
      "'Sense of community 1': 'Sense of Community 1'\n",
      "'Sense of community 2': 'Sense of Community 2'\n",
      "'Sense of community 3': 'Sense of Community 3'\n",
      "'Sense of community 4': 'Sense of Community 4'\n",
      "'Social Interaction': 'Social Interaction'\n",
      "'Social Interactions': 'Social Interaction'\n",
      "'Social interaction': 'Social Interaction'\n",
      "'Streets  Spaces': 'Streets & Spaces'\n",
      "'Streets & Spaces': 'Streets & Spaces'\n",
      "'Streets and spaces': 'Streets & Spaces'\n",
      "'Streets__Spaces_Do_buildings_streets_and_public_spaces__create_an_attractive_place_that_is_easy__to_get_around?': 'Streets & Spaces'\n",
      "'Traffic  Parking': 'Traffic & Parking'\n",
      "'Traffic & Parking': 'Traffic & Parking'\n",
      "'Traffic and parking': 'Traffic & Parking'\n",
      "'Traffic__Parking_Do_traffic_and_parking_arrangements_allow_people_to_move_around_safely_and_meet__the_communitys_needs?': 'Traffic & Parking'\n",
      "'Work  Local Economy': 'Work & Local Economy'\n",
      "'Work & Economy': 'Work & Local Economy'\n",
      "'Work and local economy': 'Work & Local Economy'\n",
      "'Work__Local_Economy_Is_there_an_active_local_economy_and_the_opportunity_to_access_good_quality_work?': 'Work & Local Economy'\n",
      "\n",
      " GPT-3.5 Normalization Mapping:\n",
      "\n",
      "'Active Travel': 'Active Travel'\n",
      "'Care Maintenance': 'Care & Maintenance'\n",
      "'Facilities Amenities': 'Facilities & Amenities'\n",
      "'Feeling Safe': 'Feeling Safe'\n",
      "'Housing Community': 'Housing & Community'\n",
      "'Identity & Belonging': 'Identity & Belonging'\n",
      "'Influence & Control': 'Influence & Control'\n",
      "'Moving Around': 'Moving Around'\n",
      "'Natural Space': 'Natural Space'\n",
      "'Play Recreation': 'Play & Recreation'\n",
      "'Public Transport': 'Public Transport'\n",
      "'Sense of community 1': 'Sense of community 1'\n",
      "'Sense of community 2': 'Sense of community 2'\n",
      "'Sense of community 3': 'Sense of community 3'\n",
      "'Sense of community 4': 'Sense of community 4'\n",
      "'Social Interaction': 'Social Interaction'\n",
      "'Streets Spaces': 'Streets & Spaces'\n",
      "'Traffic Parking': 'Traffic & Parking'\n",
      "'Work Local Economy': 'Work & Local Economy'\n",
      "\n",
      " Choose the mapping you want to apply:\n",
      "1 → GPT-3.5\n",
      "2 → GPT-4\n",
      " Using GPT-3.5 mapping.\n",
      " Normalized questions for df_2023\n",
      " Normalized questions for df_2020\n",
      " Normalized questions for df_2016\n",
      " Normalized questions for df_2018\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:23:28.490808Z",
     "start_time": "2025-08-14T05:23:05.916055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "explode_questions_into_named_ratings(unpacked_dfs)\n",
    "apply_macro_labels_from_namedquestion(unpacked_dfs, MACRO_THEME_MAP)\n",
    "flattened_dfs = flatten_demographics_columns(unpacked_dfs)\n",
    "\n",
    "unpacked_dfs = apply_type_inference_to_unpacked_dfs(unpacked_dfs)\n",
    "\n",
    "unpacked_dfs = apply_type_inference_to_unpacked_dfs(flattened_dfs)"
   ],
   "id": "fada92064c82bbf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded and updated: df_2023\n",
      "Exploded and updated: df_2020\n",
      "Exploded and updated: df_2016\n",
      "Exploded and updated: df_2018\n",
      " Added macro_label from question_label to df_2023\n",
      " Added macro_label from question_label to df_2020\n",
      " Added macro_label from question_label to df_2016\n",
      " Added macro_label from question_label to df_2018\n",
      " Flattened demographics in df_2023 → stored as df_2023_flat\n",
      " Flattened demographics in df_2020 → stored as df_2020_flat\n",
      " Flattened demographics in df_2016 → stored as df_2016_flat\n",
      " Flattened demographics in df_2018 → stored as df_2018_flat\n",
      " Inferred dtypes for df_2023\n",
      " Inferred dtypes for df_2020\n",
      " Inferred dtypes for df_2016\n",
      " Inferred dtypes for df_2018\n",
      " Inferred dtypes for df_2023_flat\n",
      " Inferred dtypes for df_2020_flat\n",
      " Inferred dtypes for df_2016_flat\n",
      " Inferred dtypes for df_2018_flat\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "one shot + cot + instruction + gpt 4",
   "id": "1a1bb7eaaec0739f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:41:06.865351Z",
     "start_time": "2025-08-14T05:41:06.813152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from typing import TypedDict, Optional\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens(text, model_name=\"gpt-4\"):\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "#   Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "\n",
    "#   Replace with your real yearly DataFrames\n",
    "df_2016 = df_2016_flat\n",
    "df_2018 = df_2018_flat\n",
    "df_2023 = df_2023_flat\n",
    "df_2020 = df_2020_flat\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    code: Optional[str]\n",
    "    result: Optional[pd.DataFrame]\n",
    "    summary: Optional[str]\n",
    "    error: Optional[str]         # ←  to capture execution errors\n",
    "    feedback: Optional[str]      # ←  \"correct\" or \"incorrect\"\n",
    "\n",
    "def extract_dataframe_info(df, year, questions_col='question_label', macro_col='macro_label'):\n",
    "    columns_info = [(col, str(df[col].dtype)) for col in df.columns]\n",
    "\n",
    "    # Collect unique question texts from string-based 'question_label' column\n",
    "    question_label = []\n",
    "    if questions_col in df.columns:\n",
    "        question_label = sorted(\n",
    "            df[questions_col].dropna().astype(str).unique().tolist()\n",
    "        )\n",
    "\n",
    "    # Collect unique macro_label values\n",
    "    macro_values = []\n",
    "    if macro_col in df.columns:\n",
    "        macro_values = sorted(df[macro_col].dropna().unique().tolist())\n",
    "\n",
    "    return {\n",
    "        'year': year,\n",
    "        'columns_info': columns_info,\n",
    "        'question_label': question_label,\n",
    "        'macro_values': macro_values,\n",
    "    }\n",
    "\n",
    "def llm_generate_code_node(state: State) -> State:\n",
    "    query = state[\"query\"]\n",
    "    error = state.get(\"error\", \"\")\n",
    "    feedback = state.get(\"feedback\", \"\")\n",
    "    dfs_info = [\n",
    "        extract_dataframe_info(df_2016, 2016, questions_col=\"question_label\"),\n",
    "        extract_dataframe_info(df_2018, 2018, questions_col=\"question_label\"),\n",
    "        extract_dataframe_info(df_2023, 2023, questions_col=\"question_label\"),\n",
    "        extract_dataframe_info(df_2020, 2020, questions_col=\"question_label\"),\n",
    "    ]\n",
    "\n",
    "    # prompt_str = build_prompt(dfs_info)\n",
    "\n",
    "    prompt_str = build_prompt(dfs_info, feedback=feedback, error=error)\n",
    "    # print(\"\\n FINAL PROMPT SENT TO GPT:\\n\")\n",
    "    print(prompt_str)\n",
    "    prompt_template = PromptTemplate(template=prompt_str, input_variables=[\"query\"])\n",
    "    llm_chain = LLMChain(llm=ChatOpenAI(model=\"gpt-4\", temperature=0.5), prompt=prompt_template)\n",
    "    # model=\"gpt-4-turbo\"\n",
    "    # llm_chain = LLMChain(llm=ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.5), prompt=prompt_template)\n",
    "    # llm_chain = LLMChain(llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5), prompt=prompt_template)\n",
    "\n",
    "    with get_openai_callback() as cb:\n",
    "        raw_code = llm_chain.run({\"query\": query}).strip()\n",
    "        print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "        print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "        print(f\" Total Tokens: {cb.total_tokens}\")\n",
    "        print(f\" Estimated Cost: ${cb.total_cost:.4f}\")\n",
    "\n",
    "    raw_code = llm_chain.run({\"query\": query}).strip()\n",
    "\n",
    "    match = re.search(r\"```python(.*?)```\", raw_code, re.DOTALL)\n",
    "    cleaned_code = match.group(1).strip() if match else raw_code.strip()\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"code\": cleaned_code,\n",
    "        \"result\": None,\n",
    "        \"error\": None,     # Clear previous error\n",
    "        \"feedback\": None      # Clear previous feedback\n",
    "    }\n",
    "\n",
    "def execute_code_node(state: State) -> State:\n",
    "    local_vars = {\n",
    "        \"df_2016\": df_2016,\n",
    "        \"df_2018\": df_2018,\n",
    "        \"df_2023\": df_2023,\n",
    "        \"df_2020\": df_2020,\n",
    "        \"pd\": pd,\n",
    "    }\n",
    "    error_msg = None\n",
    "\n",
    "    try:\n",
    "        exec(state[\"code\"], {}, local_vars)\n",
    "        result = local_vars[\"result\"] if \"result\" in local_vars else None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"{type(e).__name__}: {e}\"  # capture exception type and message\n",
    "        print(\"Error during execution:\", error_msg)\n",
    "        result = None  # or keep the error message in result if you want fallback behavior\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"query\": state[\"query\"],\n",
    "        \"code\": state[\"code\"],\n",
    "        \"result\": result,\n",
    "        \"error\": error_msg,\n",
    "        \"feedback\": None\n",
    "    }\n",
    "\n",
    "def llm_summarize_node(state: State) -> State:\n",
    "    result = state[\"result\"]\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    # Convert result to string (smartly)\n",
    "    if isinstance(result, pd.DataFrame):\n",
    "        obs = result.to_markdown(index=False) if len(result) <= 10 else result.head().to_markdown(index=False)\n",
    "    else:\n",
    "        obs = str(result)\n",
    "\n",
    "    # Generic summarization prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "You are a helpful analyst.\n",
    "\n",
    "User Question:\n",
    "{query}\n",
    "\n",
    "Result:\n",
    "{obs}\n",
    "\n",
    "Instructions:\n",
    "1. Interpret the result in the context of the user question.\n",
    "Reason to understand the frame in which question is asked:\n",
    "- Check the headers or labels in case of tabular data.\n",
    "-  If it's a number or a single value, infer what it can mean for user query like a bolean value\n",
    "- If it relates to polarity or sentiment, treat values > 0.1 as positive, < -0.1 as negative, and between as neutral.\n",
    "- If it’s a string, extract the meaningful insight or decision from it.\n",
    "\n",
    "Format:\n",
    "Thought: Reason through what the result shows.\n",
    "Answer: Provide a concise, human-readable summary that answers the question clearly.\n",
    "\"\"\",\n",
    "        input_variables=[\"query\", \"obs\"],\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0), prompt=prompt)\n",
    "    # chain = LLMChain(llm=ChatOpenAI(model=\"gpt-4\", temperature=0), prompt=prompt)\n",
    "\n",
    "\n",
    "    summary = chain.run({\"obs\": obs, \"query\": query}).strip()\n",
    "\n",
    "    return {\n",
    "        \"query\":   query,\n",
    "        \"code\":    state[\"code\"],\n",
    "        \"result\":  result,\n",
    "        \"summary\": summary,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Construct LangGraph workflow\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"generate_code\", llm_generate_code_node)\n",
    "builder.add_node(\"execute_code\", execute_code_node)\n",
    "builder.add_node(\"summarize\", llm_summarize_node)\n",
    "builder.set_entry_point(\"generate_code\")\n",
    "builder.add_edge(\"generate_code\", \"execute_code\")\n",
    "builder.add_edge(\"execute_code\", \"summarize\")\n",
    "\n",
    "#first one\n",
    "# def build_prompt(dfs_info, query_placeholder=\"{query}\"):\n",
    "def build_prompt(dfs_info, query_placeholder=\"{query}\", feedback: str = \"\", error: str = \"\"):\n",
    "    prompt_blocks = []\n",
    "    for info in dfs_info:\n",
    "        year = info['year']\n",
    "        columns_desc = \"\\n\".join(f\"- `{col}` ({dtype})\" for col, dtype in info['columns_info'])\n",
    "        # question_label_str = \"\\n\".join(f\"• {q}\" for q in info.get(\"question_label\", [])) or \"[]\"\n",
    "        question_label_str = \"[\" + \", \".join(f'\"{q}\"' for q in info.get(\"question_label\", [])) + \"]\"\n",
    "\n",
    "        macro_str = str(info['macro_values']) if info['macro_values'] else \"[]\"\n",
    "\n",
    "        block = f\"\"\"\n",
    "  For `df_{year}`:\n",
    "Columns:\n",
    "{columns_desc}\n",
    "- Each respondent has answered multiple survey questions so there are multiple rows for each 'id'.\n",
    "The `question_label` column contains survey questions related to topics such as:\n",
    "{question_label_str}\n",
    "\n",
    "The `macro_label` column contains values:\n",
    "{macro_str}\n",
    "\"\"\"\n",
    "        prompt_blocks.append(block.strip())\n",
    "\n",
    "    full_schema = \"\\n\\n\".join(prompt_blocks)\n",
    "\n",
    "    # Inject feedback dynamically here (this part was broken in your version)\n",
    "    feedback_lines = []\n",
    "    if feedback == \"incorrect\":\n",
    "        # feedback_lines.append(\"The previous answer was marked incorrect by the user. Please revise accordingly.\")\n",
    "        feedback_lines.append(\" \")\n",
    "    if error:\n",
    "        feedback_lines.append(f\"The previous code failed with error: {error}\")\n",
    "    feedback_block = \"\\n\".join(feedback_lines)\n",
    "\n",
    "    prompt_template = f\"\"\"You are a Python assistant working with survey data across multiple years.\n",
    "\n",
    "{full_schema}\n",
    "\n",
    "Your task is as follows:\n",
    "Rule one: Write the code that never fails.\n",
    "Rule two: Never fail to follow rule one.\n",
    "- Never try to aggregate comments\n",
    "Reason on the below steps and create a plan and execute the code:\n",
    "Step 1: Understand and Analyze the User Question\n",
    "Read the user’s question carefully, which may be phrased naturally and informally.\n",
    "Internally analyze which columns or fields of the DataFrame are relevant to answer this question.\n",
    "Do not directly produce Python code or answers yet.\n",
    "Use your reasoning to map the user’s intent to the DataFrame structure and data fields.\n",
    "If the question is unclear, irrelevant, or unrelated to the DataFrame columns, respond with code to pri nt exactly:\n",
    "\"please clarify\"\n",
    "Identify if they are referring to any macro label or question label\n",
    "Step 2: Identify Question Type\n",
    "Determine if the question is pinpointed (fact-based) or detailed/explanatory based on wording cues:\n",
    "If the question starts or contains words like \"which\", classify it as a pinpointed question expecting a concise answer.\n",
    "If it contains phrases like \"comment upon\", \"explain\", \"describe\", or similar, classify it as a detailed/explanatory question expecting a fuller explanation. Use analytical function based upon this reasoning.\n",
    "\n",
    "Step 3:\n",
    "\n",
    "1. First, check whether the user's query matches or closely resembles any question in the `question_label` column. The user may input a partial string — treat it as a fuzzy match. If found, prioritize filtering or analyzing based on that. Use this value appropriately in coding.\n",
    "2. Only fall back to `macro_label` if no relevant match is found in `question_label`.\n",
    "3. Use semantic similarity, synonyms, and context clues to align query terms to survey questions.\n",
    "4. Determine the time range requested: Is it a single year or a comparison across years and which dataframes are to be utilized?\n",
    "5. Review the data types before writing code.\n",
    "6. Handle nulls gracefully and avoid crashes from unhashable types.\n",
    "\n",
    "\n",
    "When writing code:\n",
    "- Always assign the final output to a variable called `result`.\n",
    "- Always use the DataFrame variable `df1`.\n",
    "- The `result` DataFrame must include (if present):\n",
    "  - `sentiment_label`\n",
    "  - `polarity`\n",
    "  - Relevant demographics like age, region, gender\n",
    "  -  Always reason while coding for counting tasks that weather grouping is required on the basis of  'id' or not.(even if user user does not mentions explicitly)\n",
    "- Replace nulls in `comments` with empty strings.\n",
    "- Even if no comments match, include the `comments` column with empty strings.\n",
    "- Avoid duplicate entries.\n",
    "- Use aggregate functions meaningfully.\n",
    "- Check `result.empty` before accessing row values.\n",
    "\n",
    "{feedback_block}\n",
    "Query: {query_placeholder}\n",
    "\n",
    "Return ONLY valid Python code (no markdown fences).\n",
    "\"\"\"\n",
    "    return prompt_template.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "b53bdedf9be0eaca",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T05:41:07.846766Z",
     "start_time": "2025-08-14T05:41:07.831061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def run_query_with_retries(query, builder, max_retries=5, interactive_feedback=True):\n",
    "    \"\"\"\n",
    "    Executes a query using the provided builder with automatic retries.\n",
    "\n",
    "    Args:\n",
    "        query (str): The natural language query to execute.\n",
    "        builder: The LangGraph builder instance (already configured).\n",
    "        max_retries (int): Maximum number of retry attempts.\n",
    "        interactive_feedback (bool): Whether to ask for manual correction feedback.\n",
    "\n",
    "    Returns:\n",
    "        dict: Final output containing 'code', 'result', and 'summary'.\n",
    "    \"\"\"\n",
    "    success_attempt = None\n",
    "    final_output = None\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        print(f\"\\nAttempt {attempt} of {max_retries}\")\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        output = builder.compile().invoke({\"query\": query})\n",
    "        result = output.get(\"result\")\n",
    "        error = output.get(\"error\")\n",
    "\n",
    "        if error:\n",
    "            print(f\" Execution failed with error: {error}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Retry with feedback about the error\n",
    "            output = builder.compile().invoke({\n",
    "                \"query\": query,\n",
    "                \"feedback\": \"incorrect\",\n",
    "                \"error\": error\n",
    "            })\n",
    "            result = output.get(\"result\")\n",
    "            error = output.get(\"error\")\n",
    "\n",
    "            if error:\n",
    "                print(f\" Retry also failed with error: {error}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\" Recovered from failure on attempt {attempt}.\")\n",
    "                final_output = output\n",
    "                success_attempt = attempt\n",
    "                break\n",
    "        else:\n",
    "            print(f\" Successfully executed query on attempt {attempt}. Result: {result}\")\n",
    "            final_output = output\n",
    "            success_attempt = attempt\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(\" All retries exhausted. Query failed.\")\n",
    "        return None\n",
    "\n",
    "    # Display final output\n",
    "    print(f\"\\n Final Output (attempt {success_attempt}):\")\n",
    "    print(\" Generated Code:\")\n",
    "    print(final_output[\"code\"])\n",
    "    print(\"\\nExecution Result:\")\n",
    "    print(final_output[\"result\"])\n",
    "    print(\"\\nNLP Question:\", query)\n",
    "    print(\"\\nSummary:\")\n",
    "    print(final_output[\"summary\"])\n",
    "\n",
    "    # Optional manual feedback loop\n",
    "    if interactive_feedback:\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(2)\n",
    "        user_feedback = input(\"\\nWas this answer correct? (y/n): \").strip().lower()\n",
    "        if user_feedback == \"n\":\n",
    "            print(\"\\nRerunning with feedback that previous answer was incorrect...\\n\")\n",
    "            output = builder.compile().invoke({\n",
    "                \"query\": query,\n",
    "                \"feedback\": \"incorrect\",\n",
    "                \"error\": final_output.get(\"error\", \"\")\n",
    "            })\n",
    "\n",
    "            print(\"\\nRevised Code:\")\n",
    "            print(output[\"code\"])\n",
    "            print(\"\\nRevised Execution Result:\")\n",
    "            print(output[\"result\"])\n",
    "            print(\"\\nRevised Summary:\")\n",
    "            print(output[\"summary\"])\n",
    "            final_output = output\n",
    "\n",
    "    return final_output\n"
   ],
   "id": "aa5d0e7d16c45bbe",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T10:20:40.233291Z",
     "start_time": "2025-08-14T10:20:40.217190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query =\"How many males negatively think about parking in 2018 and 2023?\"\n",
    "final_result = run_query_with_retries(query, builder)"
   ],
   "id": "791eeeab75d93c6f",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # Run the previous cells as well and create the databases as well\n",
    "# Sample questions : Question Bank\n",
    "# 1.\t\" How have gender-based negative opinions about traffic situation evolved between 2016 and 2023\"\n",
    "# 2.\t\"Has the proportion of respondents with caring responsibilities increased or decreased over time\"\n",
    "# 3.\t“Explain the sentiment shift in stewardship from 2016 to 2023.”\n",
    "# 4.\t\"How many people provided more than 4 rating to traffic in 2016?\"\n",
    "# 5.\t\"In which year did people rate the Movement feasibility the highest?\"\n",
    "# 6.\t“Do people with mobility problems express lower sentiment in 2016?\"\n",
    "# 7.\t\"In which year did people rate the streets highest and natural space lowest?\"\n",
    "# 8.\t\"Do disabled respondents consistently give lower ratings?\"\n",
    "# 9.\t\"Is there a correlation between rating and sentiment polarity across years?\"\n",
    "# 10.\t\"What is the count of unique comments per macro_label in 2023?\"\n",
    "# 11.\t\"how many people re in the category of 55-64 age group in 2016?”\n",
    "# 12.\t“Explain the shift in the sentiment of people of who had children in terms of play and recreation”\n",
    "# 13.\tWhich age saw the best overall sentiment change over the years?\n",
    "# 14.\taverage rating of spaces in 2020 and also what was the mean of count of that category in 2018\"\n",
    "# 15.\t“How many males negatively think about parking in 2018 and 2023?\"\n"
   ],
   "id": "2ecd1fab2a5fd9fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ingestion",
   "id": "412d49ef8cba5f4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "26155b0ed040efde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T01:16:38.913913Z",
     "start_time": "2025-08-13T01:16:26.964716Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting DataFrame into table: df_2016_flat_1\n",
      "Inserting DataFrame into table: df_2018_flat_2\n",
      "Inserting DataFrame into table: df_2020_flat_3\n",
      "Inserting DataFrame into table: df_2023_flat_4\n",
      " All DataFrames inserted successfully!\n",
      " Done in 11.94 seconds\n"
     ]
    }
   ],
   "execution_count": 101,
   "source": [
    "# Example usage\n",
    "start = time.time()\n",
    "insert_all_flat_dataframes(\n",
    "    unpacked_dfs,\n",
    "    db_name=\"thematic_yearly_survey\",\n",
    "    user=\"postgres\",\n",
    "    password=\"PUT OWN PASSWORD\",  # Replace with your actual password\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "print(f\" Done in {time.time() - start:.2f} seconds\")\n",
    "\n"
   ],
   "id": "f2330dafe7b74ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### mongo ingestion",
   "id": "e28a2749c5b79b5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T01:01:13.130249Z",
     "start_time": "2025-08-13T01:01:06.249009Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inserted 25564 documents into MongoDB collection 'df_2016_flat'\n",
      " Inserted 20916 documents into MongoDB collection 'df_2018_flat'\n",
      " Inserted 67368 documents into MongoDB collection 'df_2020_flat'\n",
      " Inserted 35504 documents into MongoDB collection 'df_2023_flat'\n",
      "Ingestion time 6.653691291809082 seconds\n"
     ]
    }
   ],
   "execution_count": 88,
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "def clean_dataframe_for_mongo(df):\n",
    "    \"\"\"Convert NaNs and pandas.NA to None for MongoDB compatibility\"\"\"\n",
    "    return df.where(pd.notna(df), None)\n",
    "\n",
    "def insert_all_flat_dataframes_to_mongodb(unpacked_dfs, db_name=\"thematic_survey\", host=\"localhost\", port=27017):\n",
    "    client = MongoClient(host=host, port=port)\n",
    "    db = client[db_name]\n",
    "\n",
    "    for name, df in unpacked_dfs.items():\n",
    "        if name.startswith(\"df_\") and name.endswith(\"_flat\"):\n",
    "            collection = db[name]  # Use the exact name of the DataFrame\n",
    "\n",
    "            cleaned_df = clean_dataframe_for_mongo(df)\n",
    "            documents = cleaned_df.to_dict(orient=\"records\")\n",
    "\n",
    "            if documents:\n",
    "                collection.insert_many(documents)\n",
    "                print(f\" Inserted {len(documents)} documents into MongoDB collection '{name}'\")\n",
    "\n",
    "    client.close()\n",
    "\n",
    " # Ingest to MongoDB\n",
    "start = time.time()\n",
    "insert_all_flat_dataframes_to_mongodb(unpacked_dfs, db_name=\"thematic_survey\")\n",
    "print(\"Ingestion time\", time.time() - start , \"seconds\")"
   ],
   "id": "c6290f1ed66370be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "db76635816ed90c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
